---
title: 'Análisis estadístico de datos de Microbioma con R'
subtitle: 'Capítulo 8: Análisis univariado de comunidades'
author:
 - Equipo 4
 - Andrés Arredondo Cruz (andresabstract@gmail.com)
 - Adriana Haydé Contreras Peruyero (haydeeperuyero@gmail.com)
 - David Alberto García Estrada (david.garcia.e@cinvestav.mx)
date: "`r Sys.Date()`"
output: html_document
---

# Análisis univariado de comunidades

Dividimos el estudio de la composición de las comunidades microbianas en dos grandes componentes: 

  (a)Evaluación de hipótesis sobre diversidad taxonómica, OTU y Taxones.  
  (b) Análisis de diferencias entre grupos. 
  
El primer componente pertenece principalmente a análisis univariado de comunidades. El segundo puede ser dividido en varias técnicas multivariadas, como lo son "clustering" y  "ordinations", y la evaluación de hipótesis de análisis multivariado de  disimilitudes.  

## Comparaciones de diversidades entre dos grupos

En nuestro estudio con ratones Vdr$-/-$, uno de los propósitos es probar la diferencia de diversidades entre dos grupos (Vdr$-/-$ y ratones de tipo salvaje) en sitios fecales y cecales. Aquí ilustraremos el análisis de la comunidad univariante, y compararemos la diversidad de Shannon (calculada anteriormente en el Cap. 6 en las muestras fecales) usando varios estadísticos de prueba.

### Prueba $t$ de Welch para dos muestras

El estadístico $t$ fue introducido en 1908 por William Sealy Gosset. Una prueba $t$ de dos muestras se utiliza para probar que las medias de dos poblaciones son iguales. Se aplica más comúnmente cuando el estadístico de prueba sigue una distribución normal. Si los dos grupos tienen la misma varianza, el estadístico $t$ se puede calcular de la siguiente manera:

$$
t=\frac{\bar X_1 - \bar X_2}{^{Sp} \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}
$$
donde, $s_p = \sqrt{\frac{(n-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}$ es un estimador de desviación estándar de las dos muestras. La prueba $t$ de Welch o la prueba $t$ de varianzas desiguales es una adaptación de la prueba $t$. El estadístico de la prueba $t$ de Welch está dado por:

\[ t\ =\ \frac{\bar{X}_1-\bar{X}_2}{s_{\bar{\Delta}}}, \]

donde $s_{\bar{\Delta}}=\sqrt{\frac{s_{1}^2}{n_1}+\frac{s_2^2}{n_2}}$; $s_1^2$ y $s_2^2$ son los estimadores imparciales de la varianza de las muestras 1 y 2, respectivamente. Cuando las dos muestras tienen varianzas desiguales y tamaños de muestra desiguales, la prueba $t$ de Welch se considera más confiable (Ruxton 2006).

Por lo tanto, aquí usamos la prueba $t$ de Welch para nuestros datos de ratón Vdr$-/-$.

Primero, cargamos y calculamos la transpuesta del conjunto de datos:


```{r}
# IMPORTANTE
# Ajustamos path de trabajo según tu PC
# Mostramos directorio actual
getwd()
# Si es necesario, cambiar la ruta donde están los archivos almacenados. 
# "." significa el directorio actual. 
workingDir <-  "."
setwd(workingDir)
```

```{r}
abund_table <-  read.csv(paste0(workingDir,"/data/VdrGenusCounts.csv"),
                         row.names=1, check.names=FALSE)
abund_table <- t(abund_table)
```

Para incorporar la información del grupo del conjunto de datos directamente a la comparación, necesitamos administrar los datos. En el conjunto de datos, la información del ID de la muestra y el grupo están en una franja de caracteres. Primero los extraemos de allí.

```{r}
grouping <- data.frame(row.names = rownames(abund_table), 
                       t(as.data.frame(strsplit(rownames(abund_table),"_"))))
grouping$Location <- with(grouping, ifelse(X3%in%"drySt-28F", "Fecal", "Cecal"))
grouping$Group <- with(grouping,ifelse(as.factor(X2)%in% c(11,12,13,14,15), 
                                       c("Vdr-/-"), c("WT")))
grouping <- grouping[,c(4,5)]
grouping
```

Repetimos el calculo de la diversidad de Shannon para esta tabla, igual que en el capítulo 6.

```{r}
library(vegan)
H<-diversity(abund_table, "shannon") 
```

Luego combinamos los dataframes de la diversidad de Shannon y agrupación para crear un nuevo dataframe.

```{r}
df_H<-data.frame(sample=names(H),value=H,measure=rep("Shannon",length(H)))
df_G <-cbind(df_H, grouping)
rownames(df_G)<-NULL
df_G
```

A continuación, creamos subconjuntos de datos fecales del nuevo dataframe.

```{r}
Fecal_G<- subset(df_G, Location=="Fecal")
Fecal_G
```

Ahora, los datos están listos para el análisis estadístico. Antes de realizar la prueba de hipótesis, exploremos la distribución de los valores de diversidad de Shannon usando la función `ggplot()`. 

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Diversidad de Shannon'}
library(ggplot2)
#dividimos el gráfico en dos paneles usando facet_grid.
p<-ggplot(Fecal_G, aes(x=value))+
  geom_histogram(color="black", fill="black")+
  facet_grid(Group ~ .)
p
```

El paquete `plyr` se utiliza para calcular los valores promedio de la diversidad de Shannon de cada grupo.

```{r}
library(plyr)
#la función ddply toma input un df y arroja un df de output
mu <- ddply(Fecal_G, "Group", summarise, grp.mean=mean(value))
head(mu)
```


```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Diversidad de Shannon con líneas de media.'}
#Agregamos las líneas de la media a la gráfica
p+geom_vline(data=mu, aes(xintercept=grp.mean, color="red"),
             linetype="dashed")
```

En el histograma anterior la eliminación de Vdr de este grupo se desplaza hacia la derecha en relación con el grupo WT (hacia valores de diversidad más altos), lo que da como resultado una mayor diversidad. 

```{r}
#Usamos la prueba t de Welch para probar la hipotesis nula
fit_t <- t.test(value ~ Group, data=Fecal_G)
fit_t
```

Para probar la hipótesis nula de que no hay diferencia en la diversidad de Shannon, se utilizó una prueba $t$ de Welch que dio como resultado un valor de p = `r fit_t$p.value` (t = `r fit_t$statistic`, df = `r fit_t$parameter`). Por lo tanto, rechazamos la hipótesis nula de no diferencia a favor de la alternativa de que las diversidades de Shannon son diferentes en los dos grupos.

## Comparaciones de un taxón de interés entre dos grupos

### Comparación de la abundancia relativa utilizando la prueba de la suma de rangos de Wilcoxon

Cuando analizamos los datos de abundancia de microbiomas, no es apropiado sacar inferencias sobre la abundancia total en el ecosistema a partir de la abundancia de OTUs o abundancia de taxones en las muestras. Más bien podemos usar la abundancia relativa en la muestra para inferir la abundancia relativa de un taxón en el ecosistema. La razón subyacente es que existe una restricción de composición: todas las abundancias relativas dentro de una muestra suman a uno, lo que da como resultado datos de composición residiendo en un **simplejo** (Aitchison 1982, 1986) en lugar de residir en el espacio euclidiano. Por lo tanto, a menudo es necesario estandarizar los datos a una escala común para facilitar la comparación de la abundancia del taxón entre grupos. La forma es dividir el conteo de taxones por el número total de lecturas en 100 para convertir la abundancia en el porcentaje de lecturas en la muestra, escalar los datos a "el número de taxones por 100 lecturas".

Cuando seleccionamos un solo taxón específico para probarlo en grupos, es importante asegurarse de que el taxón especificado se base en una hipótesis o teoría para reducir la posibilidad de inflar la tasa de falsos positivos (es decir, rechazar la hipótesis nula cuando no debería ser rechazada).

Vdr en ratones afecta sustancialmente la diversidad beta e influencia constantemente taxones bacterianos individuales, como los Parabacteroides (Wang et al. 2016). En esta sección, se ilustra la prueba de suma de rangos de Wilcoxon para comparar Bacteroides bacterianos en el conjunto de datos de ratones Vdr utilizando muestras fecales.

Primero, verificamos la abundancia total en cada muestra.

```{r}
apply(abund_table,1, sum)
```
Luego, calculamos la abundancia relativa dividiendo cada valor por la abundancia total de la muestra:

```{r}
#Calculamos la abundancia relativa
relative_abund_table <- decostand(abund_table, method = "total")
```

Comprobamos la abundancia total en cada muestra para comprobar que los cálculos anteriores sean correctos.

```{r}
apply(relative_abund_table, 1, sum)
```

Eche un vistazo a los datos transformados

```{r}
#Visualizamos los datos transformados
relative_abund_table[1:16,1:8]
```
Nuestra bacteria de interés **Bacteroides** está en la columna 8, subdividamosla:

```{r}
#subdividimos a los bacterioides
(Bacteroides <-relative_abund_table[,8]) 
```
Ahora, combinamos Bacteroides y los dataframes agrupados y creamos subconjuntos de las muestras fecales para un uso posterior.

```{r}
#combine Bacterioides y los df agrupados y crea subconjuntos de las muestras
Bacteroides_G <-cbind(Bacteroides, grouping)
rownames(Bacteroides_G)<-NULL
Fecal_Bacteroides_G <- subset(Bacteroides_G, Location=="Fecal")
Fecal_Bacteroides_G
```
La función boxplot() se usa para generar un diagrama de caja simple de Bacteroides con el grupo

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Diagrama de caja  de Bacteroides con Vdr-/- y grupos WT en muestras fecales.'}
#cramos un boxplot con los  grupos 
#Diagrama de caja de Bacteroides con grupos Vdr-/- y WT en muestras fecales
boxplot(Bacteroides ~ Group,data=Fecal_Bacteroides_G, col=rainbow(2),
        main="Bacteroides in Vdr WT/KO mice")
```


```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Diagrama de caja  de Bacteroides con Vdr-/- y grupos WT en muestras fecales generadas usando ggplot.'}
#con ggplot generamos el boxplot con el siguente codigo
ggplot(Fecal_Bacteroides_G, aes(x=Group, y=Bacteroides,col=factor(Group))) + 
  geom_boxplot(notch=FALSE)
```

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Diagrama de caja  de Bacteroides con Vdr-/- y grupos WT en muestras fecales generadas usando ggplot con otro formato.'}
#Diagrama de caja  bacterias Bacteroides con Vdr−/− y WT en muestras fecales
#generados usando ggplot
ggplot(Fecal_Bacteroides_G, aes(x=Group, y=Bacteroides)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8, outlier.size=4) #+ 
  #layer(stat_params = list(binwidth = 2))
#el argumento bindwith=2 genera un error
```
Los diagramas de caja muestran taxones (**Bacteriodes**) en ratones WT (WT, n = 3) y para ratones  knockout de Vdr (KO, n = 5)

```{r}
#Hacemos una prueba de suma de rangos de Wilcoxon
fit_w_b <- wilcox.test(Bacteroides ~ Group,data=Fecal_Bacteroides_G)
fit_w_b
```

La prueba de Wilcoxon anterior indica que  existe una abundancia relativa estadísticamente significativa de Bacteroides entre los ratones Vdr$-/-$ y WT. Podemos concluir que Vdr knockout enriquece Bacteroides.

### Comparación de taxones presentes o ausentes utilizando la Prueba de chi-cuadrado

Una prueba de chi-cuadrado, también conocida como prueba $\chi^2$, a menudo utilizada como abreviatura de la prueba de chi-cuadrado de Pearson, fué propuesta e investigada por primera vez por Karl Pearson en 1900 (Pearson 1900). La prueba $\chi^2$ se aplica a conjuntos de datos categóricos para probar si la distribución de frecuencia observada difiere de una distribución teórica o propuesta (pruebas de bondad de ajuste) e investigar si la variable fila y la variable  columna en una tabla de contingencia son independientes entre sí (pruebas de independencia).
El estadístico de prueba de bondad de ajuste viene dado por:

$$
\chi^2= \sum_{i = 1}^{n}\frac{(O_i-E_i)^2}{E_i}=N\sum_{i = 1}^{n}\frac{(O_i/N-p_i)^2}{p_i},
$$
Donde:

<table>
    <tr>
        <td>$X^2$</td>
        <td>El estadístico de prueba de Pearson, que se acerca asintóticamente a la distribución $\chi^2$</td>
    </tr>
    <tr>
        <td>$O_i$</td>
        <td>número de observaciones de categoría $i$</td>
    </tr>
    <tr>
        <td>$N$</td>
        <td>Número total de observaciones</td>
    </tr>
    <tr>
        <td>$E_i=Np_i$</td>
        <td>Frecuencia esperada(teórica) de la categoría $i$ bajo la hipótesis nula</td>
    </tr>
    <tr>
        <td>$p_i$</td>
        <td>probabilidad de categoría $i$ en la población</td>
    </tr>
    <tr>
        <td>$n$</td>
        <td>número de celdas en la tabla</td>
    </tr>
</table>


El estadístico de prueba de independencia se da de la siguiente forma.

$$
\chi^2= \sum_{i = 1}^{r}\sum_{j = 1}^{c}\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}}=N\sum_{i,j}p_{i.}p_{.j}\left(\frac{(O_{i,j}/N)-p_{i.}p_{.j}}{p_{i.}p_{.j}}\right)^2,
$$

Donde

<table>
    <tr>
        <td>$N$</td>
        <td>Tamaño total de la muestra (la suma de todas las celdas de la tabla)</td>
    </tr>
    <tr>
        <td>$E_{ij}=Np_{i.}p_{.j}$</td>
        <td>Frecuencia esperada(teórica) bajo la hipótesis nula de independencia</td>
    </tr>
    <tr>
        <td>$p_{i.}=\frac{O_{i.}}{N}=\sum_{j=1}^{c}\frac{O_{ij}}{N}$</td>
        <td>Probabilidad de observaciones de categoría $i$ ignorando el atributo</td>
    </tr>
    <tr>
        <td></td>
        <td>de columna (probabilidad de totales de fila)</td>
    </tr>
    <tr>
        <td>$p_{.j}=\frac{O_{.j}}{N}=\sum_{i=1}^{r}\frac{O_{ij}}{N}$</td>
        <td>Probabilidad de observaciones de categoría $j$ ignorando el atributo de</td>
    </tr>
    <tr>
        <td></td>
        <td>fila (probabilidad de totales de columna)</td>
    </tr>
</table>

Como regla general, se requiere que todos los recuentos de celdas esperados sean iguales o superiores a $5$ para proporcionar una aproximación adecuada a la distribución de la distribución de Chi-cuadrado (Wackerly et al. 2002), aunque Cochran (1952) señaló que este valor podría ser tan bajo como $1$ para algunas situaciones.

En esta sección, ilustramos la prueba $\chi^2$ para comparar bacterias Parabacteroides en el conjunto de datos de ratones Vdr utilizando muestras cecales. Para ilustrar la prueba  $\chi^2$,  transformamos los datos de conteo de abundancia de Parabacteroides en una variable binaria. Los datos de conteo en la tabla de abundancia para el taxón Parabacteroides se transformarían a $0$ si el taxón está ausente en la muestra o $1$ si el taxón está presente en la muestra. Los datos transformados se resumen en la tabla 1.

| **Grupo**  | **Presencia** | **Ausencia** | **Total** |
|:----------:|:-------------:|:------------:|:---------:|
| **Vdr-/-** | 3 (60%)       | 2 (40%)      | 5         |
| **WT**     | 3 (100%)      | 0 (0%)       | 3         |

Tabla1: Distribución de la tasa de Parabacteroides en muestras Vdr $-/-$ y WT obtenidas del conjunto de datos de ratones Vdr.

Primero, observe los datos de abundancia para identificar Parabacteroides y subdividirlas.

```{r}
#Distribution of the Parabacteroides rate 
#across Vdr−/− and WT cecal samples obtained
abund_table[1:16,1:27]
(Parabacteroides <- abund_table[,27])
```

Luego, combinamos los datos subdivididos con el marco de datos de agrupación.

```{r}
#combina los datos subdivididos
Parabacteroides_G <-cbind(Parabacteroides, grouping)
rownames(Parabacteroides_G)<-NULL
```

Dado que el dataframe combinado incluye muestras fecales y cecales, subdividamos datos cecales de este dataframe

```{r}
Cecal_Parabacteroides_G <- subset(Parabacteroides_G, Location=="Cecal")
Cecal_Parabacteroides_G
```

Antes, recodificamos una variable binaria: "Presente", para la prueba de Chi-cuadrado.

```{r}
Cecal_Parabacteroides_G$Present <- ifelse((
  Cecal_Parabacteroides_G$Parabacteroides > 0), "Present","Absent")
Cecal_Parabacteroides_G
```

El siguiente código es usado para crear una prueba de Chi-cuadrado

```{r}
library(MASS) 
tbl = table(Cecal_Parabacteroides_G$Group, Cecal_Parabacteroides_G$Present) 
tbl                 
chi <- chisq.test(tbl)
chi
```


La tabla \ref{tab:tabla1} muestra la distribución de estas tasas: 3(60%) de 5 muestras cecales Vdr$-/-$ tenían Parabacteroides, mientras que 3(100%) de 3  muestras de WT sí lo tenían. Para probar la hipótesis nula de que no hay diferencia en las tasas de ocurrencia entre los dos grupos, una prueba de chi-cuadrado dio un $p-$valor de `r chi$p.value` ($X$-cuadrado = `r chi$statistic`, df = `r chi$parameter`), por lo que *no podemos rechazar la hipótesis nula de que no hay diferencia entre los dos grupos* y concluir que no tienen tasas diferentes de ocurrencia. Tenga en cuenta que debido al pequeño tamaño de la muestra, hay un mensaje de advertencia en la salida. Por lo general, si los valores de las celdas son pequeños (como $<5$) en la tabla de contingencia, la prueba de chi-cuadrado puede ser incorrecta, entonces se aplica una prueba de exactitud de Fisher [ver](http://www.biostathandbook.com/small.html):

```{r}
#prueba de exactitud de fisher
fisher <- fisher.test(tbl)
fisher
```

El resultado de la prueba de exactitud de Fisher tampoco es significativo con un $p-$valor de `r fisher$p.value`, *lo que es consistente con la prueba de Chi-cuadrado*. Sin embargo, es difícil tener conclusiones sobre la prueba con el intervalo de confianza infinito.

## Comparación entre más de dos grupos usando ANOVA

### ANOVA de una vía 

El análisis de varinza (ANOVA) fue propuesto por Ronal Fisher en 1918 y se hizo bien conocido después de la publicación del libro de Fisher, *"Statitiscal Methods for Research Workers"* en 1925. El ANOVA generaliza la prueba de t de dos muestras a más de dos grupos. La **Hipótesis nula** del ANOVA es: *Todas las medias de grupos comparados son iguales*. El análisis usando ANOVA se basa en un supuesto de *Normalidad* de los datos subyacentes. Sin embargo, la composición de la mayoría de los datos de comunidades microbiana, especialmente datos multivariados, no están normalmente distribuidos, por lo tanto, ANOVA solo es usaod para comparar análisis univariado de mediciones de alfa diversidad. Para datos de composición comunitaria multivariante, se aplica una versión no paramétrica La formación de la estadística de prueba se realiza mediante la partición tradicional de la suma de cuadrados (división de la variación). La ecuación de definición de la muestra varianza es

$$
s^{2} = \frac{1}{n - 1} 
{\sum^{n}_{i=1}(y_{i} - \bar y)^{2}}
$$

donde $s^{2} = $ varianza de la muestra. La varianza de la muestra es calculada por la suma de cuadados (SS) dividido por $n-1$ (grados de libertad, DF). El resultado es llamado media cuadrada (MS) y los términos cuadrados son desviaciones de la media simple. 
La técnica fundamental del ANOVA divide la suma total de cuadrados (SS) de desviaciones en dos componentes: suma de cuadrados relacionados con el tratamiento y suma de cuadrados relacionados con el error:

$$
SS_{Total} = SS_{Tratamientos} + SS_{Error}
$$

El número de grados de libertad, DF, pueden ser particionados de una manera similar:

$$
DF_{Total} = DF_{Tratamientos} + DF_{Error}
$$

La prueba $F$ es usada para comparar los factores de la desviación total. El valor $F$ es obtenido por la división de la varianza entre tratamientos por la varianza dentro de tratamientos. La prueba estadística $F$ en un ANOVA de una vía esta dado por:

$$
F = \frac{MS_{Tratamientos}}{MS_{Error}} = \frac{SS_{Tratamientos}/(K-1)}{SS_{Error}/(N-1)} 
$$

donde $MS =$ media cuadrada, $K =$ número de tratamientos y $N =$ número total de muestras.
Para ilustrar el ANOVA en el estudio de la composición de la comunidad del microbioma, utilizamos los datos de nuestro ratón $Vdr^{-/-}$. Una hipótesis de este estudio es que el estado de $Vdr$ y la localización intestinal no tienen efectos en la comunidad bacteriana del intestino. Analizamos las medidas de diversidad alfa de Chao 1 utilizando ANOVA para abordar esta hipótesis.
Los siguientes códigos crean un marco de datos de riqueza Chao1 y añaden la información de los grupos a este marco de datos

```{r}
CH <- estimateR(abund_table)[2,] 
df_CH <- data.frame(sample = names(CH), value = CH, 
                    measure = rep("Chao1", length(CH))) 
df_CH_G <- cbind(df_CH, grouping)
rownames(df_G) <- NULL
df_CH_G
```

Los nuevos 4 niveles de grupo son generados usando interacción de Locación y Grupo

```{r}
df_CH_G$Group4 <- with(df_CH_G, interaction(Location,Group))
df_CH_G
```

Exploramos el índice de Chao usando `boxplot()`

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Boxplot del índice Chao 1 con cuatro grupos generados usando la función `boxplot()`.'}
boxplot(value~Group4, data=df_CH_G, col = rainbow(4), main="Chao1 index")
```

El siguiente `ggplot()` genera una alta calidad de boxplot para publicarlo

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Boxplot del índice Chao 1 con cuatro grupos generados usando la función `ggplot()`.'}
library(ggplot2)
p <- ggplot(df_CH_G, aes(x=Group4, y=value), 
            col=rainbow(4), main="Chao1 index") + 
  geom_boxplot()
p + coord_flip()
ggplot(df_CH_G, aes(x = Group4, y = value, col = factor(Group4))) + 
  geom_boxplot(notch = FALSE)
```

Además de la inspección visual de la normalidad de los datos subyacentes, la homogeneidad de varianza puede ser probada. Sokal y Rohlf (2011) describen tres pruebas de este tipo: la prueba de homogeneidad de Bartlett, la prueba $F_{max}$ de Hartley y la prueba log-anova o Scheffé-Box. Para proceder a la comprobación del uso de ANOVA, primero debemos comprobar la homogeneidad de las varianzas. El software R proporciona dos pruebas: la prueba de Bartlett y la prueba de Fligner-Killeen.
Para ilustrar la prueba de homogeneidad de varianzas, utilizamos las medidas de riqueza Chao 1 de los datos de los ratones $Vdr^{-/-}$ y WT de las localizaciones fecales y cecales. La hipótesis nula ($H_0$) de es que todas las varianzas de los cuatro grupos son iguales. Comenzamos con la prueba de Bartlett. Para facilitar el procesamiento de la prueba de Bartlett de Bartlett, utilizamos la función `select()` del paquete dplyr para seleccionar el grupo pertinente y las columnas de valor de Chao 1.

```{r}
library(dplyr)

df_CH_G4 <- dplyr::select(df_CH_G, Group4, value)
df_CH_G4
```

Los códigos R siguientes conducen a la prueba Barlett de homogeneidad de varanzas:

```{r}
# No corre
# bartlett.test(df_CH_G4, Group4) 
```

La función nos da el valor K al cuadrado de las pruebas estadísticas y el valor $p$. Muestra que la hipótesis nula puede rechazarse al nivel del 5%. Como alternativa, podemos comparar el K-cuadrado de Bartlett con el valor de las tablas de chi-cuadrado, utilizando el mismo nivel de alfa y grados de libertad en la función `qchisq()`. Si Chi-cuadrado > K-cuadrado de Bartlett, aceptamos la hipótesis nula $H_0$ (homogeneidad de varianzas), de lo contrario rechazamos la hipótesis nula.

```{r}
qchisq(0.95, 1)
```

Como la Chi-cuadrado es menor que la K-cuadrado de Bartlett, rechazamos la hipótesis nula $H_0$ y concluimos que las varianzas no son iguales. 
Ahora utilizamos la prueba de Fligner-Killeen para comprobar la homocedasticidad. La sintaxis como a continuación es bastante similar.

```{r}
fligner.test(df_CH_G4, Group4)
```

Las conclusiones son similares a las de la prueba de Bartlett: las varianzas no son iguales. Sin embargo, a efectos de ilustración, procedemos a analizar los datos mediante ANOVA independientemente de los resultados de la prueba de homegeneidad de varianzas. Los siguientes códigos R se ajustan al modelo:

```{r}
fit = lm(formula = value~Group4, data = df_CH_G)
```

Entonces analizamos el modelo de ANOVA

```{r}
anova(fit)
```

O solo usamos el siguiente codigo: la función `aov()` anidade dentro de la función `summary()`.

```{r}
summary(aov(value~Group4, data=df_CH_G))
```

Podemos imprimir el intercepto usando lo siguiente

```{r}
aov_fit <- aov(value~Group4, data = df_CH_G) 
summary(aov_fit, intercept=T) 
```

Como el valor $p$ > 0.05, aceptamos la hipótesis $H_0$: las cuatro medias no son diferentes. Podemos comprar el valor $F$ con el valor tabulado de $F$:

```{r}
qf(0.95, 12, 3)
```

Debido a que el valor tabulado de $F$ es más grande que el computado valor $F$, aceptamos la $H_0$.
Los resultados del ANOVA son un poco desordenados. Puede utilizar el paquete broom para obtener las tablas ordenadas y más informativas.

```{r}
#install.packages("mnormt")
library("broom")
tidy(aov_fit)
augment(aov_fit)
glance(aov_fit)
```

### Comparaciones múltiples Pareadas y de Tukey

Los resultados del ANOVA dan la prueba global de diferencia de grupos (en este caso, 4 grupos con combinación fecal, cecal, $Vdr^{-/-}$ y WT). Nuestro propósito es probar también cada diferencia de pares asociada a la riqueza de Chao 1. Los siguientes pasos sirven para ilustrar las capacidades de la prueba t por pares y las comparaciones múltiples ad hoc de Tukey en R.
Vamos a ejecutar la prueba t por pares no ajustada para los cuatro grupos. La configuración por defecto en R para esta prueba es ajustar los valores p como post hoc usando el método Holm, así que para obtener valores p no ajustados, debe especificar `p.adjust = "none"`. El valor por defecto de R asume la homogeneidad de la varianza, por lo que no es necesario especificar `pool. sd = T`. Si sus datos tienen una varianza desigual, debe utilizar `pool.sd = F`.

```{r}
# Pruebas de diferencias de medias por pares
pairwise.t.test(df_CH_G$value, df_CH_G$Group4, 
                p.adjust = "none", pool.sd = T) 
```

Si no hacemos ningún ajuste a nuestros valores $p$, hay diferencias estadísticamente entre $Vdr^{-/-}$ fecal, $Vdr^{-/-}$ cecal, y marginalmente diferencias estadísticas entre WT cecal y $Vdr^{-/-}$ cecal. Estas diferencias se visualizan en el `boxplot`.
Como observamos, la función `p.adjust()` está anidada dentro de la función `pairwise.t.test()` de pares. Esta es una función básica y muy útil de R. Puede utilizarse para controlar el error de tipo I de la familia. La función `p.adjust()` puede anidarse en otra función, o ser llamada de forma independiente. En una llamada independiente, la sintaxis se da a continuación:
$$
p.adjust(p, method = p.adjust.methods, n =  length(p))
$$

donde, $p =$ vector numérico de valores $p$, $método =$ método de corrección, $n =$ número de comparaciones, debe ser al menos $length(p)$. Los métodos de ajuste incluyen `c("bonferroni", "holm", "hochberg", "hommel", "BH", "BY", "fdr", "none")`. Donde "bonferroni" es la corrección de Bonferroni en la que los valores $p$ se multiplican por el número de comparaciones; "holm", "hochberg", "hommel", "BH", "BY", "fdr" se refieren a Holm (1979), Hochberg (1988), Hommel (1988), Benjamini y Hochberg (1995) y Benjamini y Yekutieli (2001), y "fdr" es un alias de "BH". Son correcciones menos conservadoras.

```{r}
# Ajuste conservador de Bonferroni
pairwise.t.test(df_CH_G$value, df_CH_G$Group4, 
                p.adjust = "bonferroni", pool.sd = T)
# Método de Holm
pairwise.t.test(df_CH_G$value, df_CH_G$Group4, 
                p.adjust = "holm", pool.sd = T)
# Método de Benjamini & Hochberg(BH)
pairwise.t.test(df_CH_G$value, df_CH_G$Group4,
                p.adjust= "BH", pool.sd = T)
# Método de Benjamini & Yekutieli
pairwise.t.test(df_CH_G$value, df_CH_G$Group4,
                p.adjust = "BY", pool.sd = T)
```

Los cuatro ajustes anteriores no ofrecen diferencias significativas en las comparaciones por pares. Los ajustes conservadores de Bonferroni y Benjamini & Yekutieli tienen los mayores valores $p$. Con el método de Benjamini y Hochberg ninguna de las comparaciones son significativas, pero sus valores p ajustados son menores. El método Benjamini & Hochberg es más potente en este caso. Tanto el método de Benjamini & Hochberg (BH) como el de Benjamini & Yekutieli (BY) son para ajustar la "tasa de falsos descubrimientos" (FDR). En realidad no es un verdadero control de error por familia. Los métodos de la Falsa Tasa de Descubrimiento encuentran los mismos resultados: todas las comparaciones por pares no presentan diferencias significativas.
A continuación, vamos a mostrar el uso de la función `TukeyHSD()` para hacer comparaciones múltiples de Tukey de medias y obtener sus intervalos de confianza. La forma de llamar a esta función es similar a la función `summary()`. Toma la variable del cálculo original de ANOVA original como uno de sus argumentos.

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Gráfico de Tukey de comparaciones múltiples de medias y su intervalo de confianza en datos de ratón $Vdr^{-/-}$`.'}
# Comparaciones multiple de medias Tukey
TukeyHSD(aov_fit, conf.level=.95)  
# Gráfico
plot(TukeyHSD(aov(df_CH_G$value~df_CH_G$Group4), conf.level=.95))
```

Este gráfico representa todas las pruebas posibles por pares y los valores $p$, así como los intervalos de confianza del 95%. El nivel de confianza del 95% por defecto puede cambiarse según su elección. Dado que todas las líneas de confianza cruzan 0, para este ejemplo, no hay términos significativamente diferentes tras el ajuste mediante comparaciones múltiples de Tukey.

## Comparaciones entre más de dos grupos usando la prueba de Kruskal-Wallis

### Prueba de Kruskal-Wallis

La prueba de Kruskal-Wallis o ANOVA unidireccional sobre rangos, llamada así por William Kruskal y W.Allen Wallis, es un método no paramétrico para comprobar si las muestras proceden de la misma distribución (Kruskal y Wallis 1952; Daniel 1990). *El equivalente paramétrico de la prueba de Kruskal-Wallis es el ANOVA de una vía*. 
La ampliación es la prueba $U$ de Mann-Whitney a más de dos grupos. La hipótesis nula de la prueba de Kruskal-Wallis es que los *rangos medios de los grupos son los mismos*. A diferencia del ANOVA unidireccional análogo, la prueba no paramétrica de *Kruskal-Wallis no asume una distribución normal de los datos subyacentes*. Se ha utilizado ampliamente en investigación del microbioma. Por ejemplo, los datos del microbioma posteriores a la secuenciación no están distribuidos normalmente y contienen algunos valores atípicos importantes. Por lo tanto, es conveniente utilizar rangos en lugar de valores reales para evitar que las pruebas se vean afectadas por la presencia de valores atípicos o por una distribución no normal. La estadística de la prueba consta de cuatro pasos principales:
+ *Paso 1*. Clasificar todos los datos de todos los grupos juntos en una única serie en orden ascendente, es decir, clasificar los datos de 1 a N ignorando la pertenencia a un grupo.
+ *Paso 2*. Asignar los valores empatados promediando su posición en el ranking.
+ *Paso 3*. Sumar los diferentes rangos, por ejemplo, $R_1$ $R_2$ $R_3$... para cada uno de los diferentes grupos.
+ *Paso 4*. Calcula la estadística de la prueba aplicando la siguiente fórmula:
$$
H = \frac{12}{n(n+1)}\sum^k_{i=1}\frac{R^{2}_{i}}{n_{i}}-3(n+1)
$$

donde
+ $H$ Prueba estadística de Kruskal-Wallis
+ $n$ número total de mediiones en todas las muestras
+ $n_{i}$ número de mediciones en la muestra de la población $i$
+ $k$ número de poblaciones
+ $R_{i}$ rango de sumas para la muestra $i$.

El estadístico de la prueba de Kruskal-Wallis es aproximadamente una distribución chi-cuadrado, con k - 1 grados de libertad si los valores de $n_{i}$ son "grandes". La aproximación se acepta generalmente como adecuada cuando cada uno de los valores de $n_{i}$ es mayor o igual a 5.

### Comparación de diversidades entre grupos

La prueba de Kruskal-Wallis o ANOVA de una vía se realiza para comparar grupos múltiples cuyos datos no siguen una distribución normal. Esta prueba es similar a la prueba de suma de rangos de Wilcoxon para dos muestras. Primero utilizamos los datos de nuestros ratones $Vdr^{-/-}$ para
ilustrar esta prueba.

```{r}
library("dplyr")
Data <- mutate(df_CH_G, Group = factor(df_CH_G$Group4,
                                       levels = unique(df_CH_G$Group4)))
```

Estadística descriptiva

```{r}
library("FSA")
Summarize(value ~ Group4, data = df_CH_G)
```

Generamos Histograma por grupo

```{r, include = TRUE, echo = TRUE, fig.pos = 'H', fig.dim = c(12,8), fig.align = "center", message=FALSE, fig.cap = 'Distribuciones de los valores entre los grupos`.'}
# Gráficos individulaes en un panel de 2X2
library("lattice")
histogram(~ value|Group4, data=df_CH_G,layout=c(2,2)) 
```

El histograma muestra que las distribuciones de los valores entre los grupos son diferentes en este caso. Ahora realizamos la prueba de Kruskal-Wallis para comparar las diferencias de medianas utilizando la función `kruskal.test()`.

```{r}
# Prueba de Kruskal-Wallis de la riqueza de Chao1
kruskal.test(value ~ Group4, data = df_CH_G) 
```

El valor de la estadística de la prueba es 5,2 con un valor $p$ superior a 0,05 y también es inferior a la tabulación chi-cuadrado:

```{r}
qchisq(0.950, 3)
```

Por tanto, aceptamos la hipótesis nula $H_0$: las medianas de los 4 grupos son estadísticamente iguales a un nivel significativo del 5%.
Generalmente, se realiza un análisis post hoc para encontrar qué niveles de los grupos son diferentes entre sí si la prueba de Kruskal-Wallis es significativa. En este caso, la prueba de Kruskal-Wallis no es significativa. A modo de ilustración, realizamos dos pruebas post hoc: La prueba de Nemenyi y la prueba de Dunn. De forma similar al ANOVA, podemos elegir un método para ajustar los valores $p$ para controlar la tasa de error familiar o para controlar la tasa de falsos descubrimientos. Al introducir `?p.adjust` en R o RStudio, aparece un enlace al documento "Adjust P-values for Multiple Comparisons". Puede consultar los detalles de los métodos de ajuste desde este enlace.

#### Prueba de Nemenyi para comparaciones múltiples \
\
La prueba de Nemenyi se realiza mediante la función `NemenyiTest()` del paquete DescTools. Primero cargamos el paquete DescTools y llamamos a la función `NemenyiTest()`. El método para ajustar los valores $p$ debe ser uno de "tukey", "chisq". En este caso elegimos el método Tukey

```{r}
library("DescTools")
# Método de Tukey para ajustar valores p
Test_N <- NemenyiTest(x = df_CH_G$value,
                 g = df_CH_G$Group4,
                 dist="tukey")
Test_N
```

La prueba de Nemenyi muestra que no hay diferencias significativas en el rango medio de la diversidad Chao 1 entre localizaciones y genotipos en las muestras fecales y cecales de vdr knockout utilizando el método de ajuste de Tukey. Sin embargo, cuando los grupos tienen números desiguales de observaciones, la prueba de Nemenyi es inadecuada, y la prueba de Dunn es apropiada (Zar 2010). 

#### Prueba de Dunn para comparaciones múltiples \
\
La prueba post hoc de Kruskal-Wallis más popular es la prueba de Dunn. Podemos realizar la prueba de Dunn utilizando la función `dunnTest()` del paquete FSA. A continuación, llamamos a la función función `dunnTest()` y utilizamos el método de Benjamini y Hochberg para ajustar los valores $p$.

```{r}
library("FSA")
# "bh" sugiere el método de Benjamini y Hochberg para ajustar los valores p
Test_N <- dunnTest(df_CH_G$value ~ df_CH_G$Group4, 
                   data = df_CH_G, method="bh")
Test_N
```

La prueba de Dunn muestra que hay una diferencia estadísticamente significativa de la diversidad Chao 1 entre las muestras cecales y fecales de $Vdr^{-/-}$. Sin embargo, después de ajustar los valores comparación múltiple con el método Benjamini-Hochberg, no hay términos estadísticamente términos estadísticamente significativos entre las localizaciones y los genotipos de las muestras.

### Encontrar taxones significativos entre los grupos

En esta sección, utilizamos la prueba de Kruskal-Wallis para ilustrar cómo encontrar taxones significativos entre los grupos. Supongamos que queremos saber si existen taxones significativos entre muestras de ratones $Vdr^{-/-}$ y WT de ubicaciones fecales y cecales. Usamos el test de prueba de Kruskal-Wallis para cada uno de los 248 taxones (bacterias) en el conjunto de datos.
Primero, normalizamos los datos de abundancia y los convertimos en un marco de datos. Un método de normalización de método de normalización es utilizar la transformación logarítmica.

```{r}
data <- log((abund_table+1)/(rowSums(abund_table)+dim(abund_table)[2]))
df <- as.data.frame(data)
```

Otro método de normalización es convertir las cuentas de abundancia en abudancia relativa

```{r}
df <- as.data.frame(abund_table/rowSums(abund_table))
```

A continuación, utilice la función `kruskal.test()` y una función iterativa de R para realizar 248 pruebas (cada una para una bacteria). La función `kruskal.test()` tiene varios componentes componentes clave:
+ La prueba es un bucle para todos los taxones (columnas) con los códigos "`for (i in 1:dim(df)[2])`".
- Para cada bucle, ejecuta la prueba de Kruskal-Wallis con los códigos "`KW_test <- kruskal.test(df[,i], g=Grupo4)`".
- Los resultados se almacenan en un marco de datos con una fila por muestra y una columna por cada valor $p$ de la prueba KW.
- Informe el número de pruebas con la función cat "`cat(paste("Kruskal-Wallis test for ", names(df)[i], " ", i, "/", dim(df)[2], "; p-value=", KW_test$p.value,"\n")", sep="")`".

```{r}
KW_table <- data.frame()
for (i in 1:dim(df)[2]) {
  # Coremos prueba KW para cada bacteria
  KW_test <- kruskal.test(df[,i], g=df_CH_G$Group4)
  # Almacenamos los resultados en el dataframe
  KW_table <- rbind(KW_table,
                    data.frame(id=names(df)[i],
                    p.value=KW_test$p.value))
  # Reportamos el número de baacteria probada
  cat(paste("Kruskal-Wallis test for ",names(df)[i]," ", i, "/", 
            dim(df)[2], "; p-value=", KW_test$p.value,"\n", sep=""))
}
```

Revisamos la tabla del data.frame para asegurarnos que la función trabaja
```{r}
# Revisamos el data.frame
head(KW_table)
```

### Pruebas múltiples y valor E, FWER y FDR

En la literatura existen varios tipos diferentes de correcciones de pruebas múltiples. Entre ellas, la corrección de Bonferroni es la más conservadora. La corrección consiste simplemente en *dividir el alfa por el número de pruebas*. Aquí pesentamos las correcciones generales de las pruebas múltiples: *Valor E*, *Tasa de error por familia (FWER)* y *FDR*.

#### Valor E \
\
El valor E es el número esperado de falsos positivos por azar cuando se hacen múltiples pruebas. Simplemente se puede multiplicar el valor $p$ por el número de taxones en que se realiza la prueba para obtenerlo: Valor E = valor p epor el número de pruebas. Tenga en cuenta que en el valor E, la corrección de base es utilizar el alfa original, el valor $p$ de las pruebas en lugar del valor $p$ nominal.

```{r}
KW_table$E.value <- KW_table$p.value * dim(KW_table)[1]
KW_table$E.value
```

Dado que el valor E no es más que multiplicar el valor $p$ por el número de pruebas, puede ser mayor que 1. Si hay muchos taxones en el marco de datos para las pruebas, este método de corrección no es fácil de encontrar los taxones significativos. Los taxones significativos son aquellos para los que el valor E es mucho menor que 1. Los siguientes códigos se utilizan para comprobar si o no los valores E se añaden al marco de datos resultante:

```{r}
# Revisamos el data.frame de resultados
head(KW_table)
```

#### FWER \
\
La FWER es la probabilidad de obtener al menos un falso positivo (error de tipo I). En En otras palabras, es la probabilidad de no rechazar la hipótesis nula $H_0$: no hay diferencias entre los grupos mientras se realizan pruebas múltiples. La fórmula es dada por:
$$
FWER = 1-(1-p-value)^T
$$

donde, T = el número de pruebas. Para evitar los errores de redondeo causados por el cálculo directo utilizando la fórmula anterior, en R es mejor calcular la FWER con una prueba de distribución binomial de cola derecha. 

```{r}
KW_table$FWER <- pbinom(q=0, p=KW_table$p.value, size=dim(KW_table)[1],
                        lower.tail=FALSE)
```

Revisamos el dataframe para ver si FWER son añadidos al data.frame de resultados

```{r}
head(KW_table)
```

#### FDR \
\
Por último, pero no por ello menos importante, está el FDR. Benjamini y Hochberg (1995) definieron la tasa de falsos descubrimientos de la siguiente manera: *FDR = proporción esperada de rechazos erróneos entre todos los rechazos*. En este caso, el FDR es la proporción de falsos positivos entre los taxones aceptados como positivos cuando se hacen múltiples pruebas. La corrección de Benjamini-Hochberg consiste en los siguientes pasos.
En primer lugar, se ordenan los valores $p$ de menor a mayor y se hace un rango (1, 2, 3,..., k,...,T); 

```{r}
# Ordenamos los valores p de menor a mayor
KW_table <- KW_table[order(KW_table$p.value, decreasing=FALSE), ]
head(KW_table)
```

Ahora calculamos el valor $q$ usando la siguiente ecuación
$$
q-value = p - value * T/k
$$

```{r}
# Calculamos el valor q
KW_table$q.value.factor <- dim(KW_table)[1] / 1:dim(KW_table)[1]
head(KW_table$q.value.factor)

KW_table$q.value <- KW_table$p.value * KW_table$q.value.factor
head(KW_table$q.value)

# Revisamos si el valor q es añadido a la tabla de resultados
head(KW_table)
```

A continuación, especifique el FDR objetivo e identifique el último elemento de la lista clasificada que tenga un valor $q$ igual o menor que el alfa especificado utilizando los siguientes códigos:

```{r}
# Ajustamos valor alfa
KW_alpha <- 0.05

# Identificamos el último elemento de la lista ranqueada con un valor q  =< alfa
last.significant.item <- max(which(KW_table$q.value <= KW_alpha))
last.significant.item
```

En nuestro caso, no hay ningún valor $q$ menor o igual al alfa especificado, por lo que el programa devuelve un infinito negativo.
Por último, muestra la tabla del marco de resultados y los taxones elegidos:

```{r}
# Mostramos algunos resultados
selected <- 1:5
print(KW_table[selected,])

diff.taxa.factor <- KW_table$id[selected]
diff.taxa <- as.vector(diff.taxa.factor)
diff.taxa
```

Debido a que en este caso no hay ningún valor $q$ menor o igual al alfa especificado = 0,05, los 5 taxones mostrados arriba no se basan en el FDR. Son los taxones elegidos con valores $p$ más pequeños. La corrección de Benjamini-Hochberg es menos estricta que las otras correcciones de pruebas múltiples presentadas anteriormente y, por lo tanto, tiene una mayor sensibilidad.
El FDR se utiliza ampliamente en el microbioma (Le Chatelier et al. 2013; Ballou et al. 2016) y en otros campos de estudio (Jungquist et al. 2010) y en muchas funciones de R.

## Resumen

En este capítulo, presentamos una variedad de métodos comunes y clásicos en todos los campos de investigación. Algunos de ellos se aplican ampliamente en los estudios del microbioma. Ilustramos estos métodos para analizar los datos del microbioma con una implementación paso a paso en el sistema R. Los lectores pueden utilizar los códigos de R y las explicaciones proporcionadas en este capítulo para analizar sus propios datos del microbioma. Nos centramos en las pruebas de hipótesis para los datos del microbioma comunitario univariante. 
